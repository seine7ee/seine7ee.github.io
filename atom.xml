<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>everything`s cola</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-01T03:12:03.789Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>seine7ee</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Keyword Extraction by TextRank</title>
    <link href="http://yoursite.com/2019/08/01/Keyword-Extraction-by-TextRank/"/>
    <id>http://yoursite.com/2019/08/01/Keyword-Extraction-by-TextRank/</id>
    <published>2019-08-01T02:58:12.000Z</published>
    <updated>2019-08-01T03:12:03.789Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Keyword-Extraction-by-TextRank"><a href="#Keyword-Extraction-by-TextRank" class="headerlink" title="Keyword Extraction by TextRank"></a>Keyword Extraction by TextRank</h1><h2 id="1-Understand-PageRank"><a href="#1-Understand-PageRank" class="headerlink" title="1. Understand PageRank"></a>1. Understand PageRank</h2><p>TextRank是一种基于PageRank的算法，通常用来进行关键词抽取和文本摘要生成。PageRank是一个用来计算网页权值的算法，我们可以把网络上的所有网页认为是一个巨大的有向图，一些网页指向另外一些网页，而在图中，一个结点就对应一个网页。如果网页A有通向网页B的连接，则这个连接就可以被认作一个从A到B的有向边。</p><p>当我们构建完一整张图以后，我么可以为网页分配权值，使用以下公式：</p><script type="math/tex; mode=display">S(V_i) = (1-d) + d * \sum_{j\in In(V_i)} { {1}\over{|Out(V_j)|} }S(V_j)</script><blockquote><p>$S(V_i)$ - the weight of webpage i</p><p>d - damping factor, in case of no outgoing links</p><p>$In(V_i)$ - inbound links of i, which is a set</p><p>$Out(V_j)$ - outgoing links of j, which is a set</p><p>$|Out(V_j)|$ - the number of outbound links</p></blockquote><p>下面用一个例子来讲述PageRank的实现过程。</p><p><img src="data:image/png;base64,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" alt="iamge"></p><p>我们可以用上面的有向图来表示网页之间的连接关系，下图中表示A有一个结点指向E，B有两个结点指向E，我们可以使用邻接矩阵来表示这个有向图。</p><p>每一行中的顶点对应的值表示从其他顶点连入该顶点的连接数，即该顶点的入度，同样地，每一列中的顶点对应的值也即该顶点的出度——即该顶点连接出去的数目。</p><div class="table-container"><table><thead><tr><th></th><th>A</th><th>B</th><th>E</th><th>F</th></tr></thead><tbody><tr><td>A</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>B</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>E</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>F</td><td>0</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div><p>根据公式${1 \over {Out(V_j)}}$，我们应对上述的矩阵作标准化处理</p><div class="table-container"><table><thead><tr><th></th><th>A</th><th>B</th><th>E</th><th>F</th></tr></thead><tbody><tr><td>A</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>B</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>E</td><td>1</td><td>0.5</td><td>0</td><td>0</td></tr><tr><td>F</td><td>0</td><td>0.5</td><td>0</td><td>0</td></tr></tbody></table></div><p> 然后，我们令所有节点的默认权值为1，完成$\sum_{j\in In(V_i){1\over|Out(V_j)|}S(V_j)}$ 的运算，具体如下：</p><script type="math/tex; mode=display">\left[\begin{matrix}    0 & 0 & 0 & 0\\    0 & 0 & 0 & 0\\    1 & 0.5 & 0 & 0\\    0 & 0.5 & 0 & 0\end{matrix}\right]*\left[\begin{matrix}    1\\    1\\    1\\    1\end{matrix}\right] = \left[\begin{matrix}    0\\    0\\    1.5\\    0.5\end{matrix}\right]</script><p>最后，经过多次迭代直到收敛，就可以得出最后的权值。因为我们预先并不知道node的最终权值，因此，具体的收敛实现则可以用相近两次的权值总和(sum(pagerank))之差来表示，如果这个差小于0.00001，就认为收敛了，即权值就是最终权值。</p><h2 id="2-使用TextRank实现Keyword-Extraction"><a href="#2-使用TextRank实现Keyword-Extraction" class="headerlink" title="2.使用TextRank实现Keyword Extraction"></a>2.使用TextRank实现Keyword Extraction</h2><p>PageRank和TextRank的基本思想是一致的，在PageRank中，node是网页，而在TextRank中，node则是单词。在关键词抽取中，我们可以把一个文本分割成许多句子，然后我们存储这些句子中特定词性的词，因为句子中的大多数单词对决定句子的重要性并不是那么有用，我们只考虑名词(NOUN)，专有名词(PROPN)，动词(VERB)等词性，当然这是可以选择的，你也可以使用所有的单词。</p><p>例如，我们使用这样一段文本，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e.g.1 将整段文本分割成几个句子 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="comment"># 导入en_core_web_sm模型</span></span><br><span class="line">nlp = spacy.load(<span class="string">'en_core_web_sm'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实验文本</span></span><br><span class="line">content = <span class="string">'''</span></span><br><span class="line"><span class="string">The Wandering Earth, described as China’s first big-budget science fiction thriller, quietly made it onto screens at AMC theaters in North America this weekend, and it shows a new side of Chinese filmmaking — one focused toward futuristic spectacles rather than China’s traditionally grand, massive historical epics. At the same time, The Wandering Earth feels like a throwback to a few familiar eras of American filmmaking. While the film’s cast, setting, and tone are all Chinese, longtime science fiction fans are going to see a lot on the screen that reminds them of other movies, for better or worse.</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将文本转换为一个nlp对象</span></span><br><span class="line">doc = nlp(content)</span><br><span class="line"><span class="comment"># 打印文本中的句子</span></span><br><span class="line"><span class="keyword">for</span> sents <span class="keyword">in</span> doc.sents:</span><br><span class="line">    print(sents.text)</span><br><span class="line">    </span><br><span class="line">[out]:</span><br><span class="line"><span class="comment"># 实验文本被分成了三句话</span></span><br><span class="line"></span><br><span class="line">The Wandering Earth, described <span class="keyword">as</span> China’s first big-budget science fiction thriller, quietly made it onto screens at AMC theaters <span class="keyword">in</span> North America this weekend, <span class="keyword">and</span> it shows a new side of Chinese filmmaking — one focused toward futuristic spectacles rather than China’s traditionally grand, massive historical epics.</span><br><span class="line"></span><br><span class="line">At the same time, The Wandering Earth feels like a throwback to a few familiar eras of American filmmaking.</span><br><span class="line"></span><br><span class="line">While the film’s cast, setting, <span class="keyword">and</span> tone are all Chinese, longtime science fiction fans are going to see a lot on the screen that reminds them of other movies, <span class="keyword">for</span> better <span class="keyword">or</span> worse.</span><br></pre></td></tr></table></figure><p>如果要进行关键词的抽取，那么主要包括以下几个内容：</p><ul><li>文本分割成句子，保存每一句中特定词性的单词(表征词 - tokens)</li><li>以每一句为单位，获得该句子中指定窗口大小的pair，最终得到整个文本的token_pairs集合</li><li>获得所有的tokens的集合，即该文本的表征词汇集合 - vocab</li><li>根据获得的vocab和token_pairs，来得到文本图的矩阵表示，并将矩阵归一化</li><li>迭代计算出每个token的weight</li><li>(可选操作)向STOP_WORDS中加入自定义的STOP_WORDS</li><li>对权值进行排序</li></ul><h2 id="pre-option"><a href="#pre-option" class="headerlink" title="pre-option"></a>pre-option</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> spacy.lang.en.stop_words <span class="keyword">import</span> STOP_WORDS</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line">nlp = spacy.load(<span class="string">"en_core_web_sm"</span>)</span><br><span class="line">content = <span class="string">'''</span></span><br><span class="line"><span class="string">The Wandering Earth, described as China’s first big-budget science fiction thriller, quietly made it onto screens at AMC theaters in North America this weekend, and it shows a new side of Chinese filmmaking — one focused toward futuristic spectacles rather than China’s traditionally grand, massive historical epics. At the same time, The Wandering Earth feels like a throwback to a few familiar eras of American filmmaking. While the film’s cast, setting, and tone are all Chinese, longtime science fiction fans are going to see a lot on the screen that reminds them of other movies, for better or worse.</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">doc = nlp(content)</span><br></pre></td></tr></table></figure><h2 id="1-文本分割成句子，保存每一句中特定词性的单词"><a href="#1-文本分割成句子，保存每一句中特定词性的单词" class="headerlink" title="1. 文本分割成句子，保存每一句中特定词性的单词"></a>1. 文本分割成句子，保存每一句中特定词性的单词</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sentence_segment</span></span><br><span class="line"></span><br><span class="line">candidate_pos = [<span class="string">'NOUN'</span>, <span class="string">'PROPN'</span>]</span><br><span class="line">sentences = []</span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> doc.sents:</span><br><span class="line">    selected_word = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sent:</span><br><span class="line">        <span class="keyword">if</span> word.pos_ <span class="keyword">in</span> candidate_pos <span class="keyword">and</span> word.is_stop <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">            selected_word.append(word)</span><br><span class="line">    sentences.append(selected_word)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">    print(sent, <span class="string">"\n"</span>)</span><br><span class="line">   </span><br><span class="line">[out]</span><br><span class="line">[Wandering, Earth, China, ’s, budget, science, fiction, thriller, screens, AMC, theaters, North, America, weekend, filmmaking, —, spectacles, China, ’s, epics] </span><br><span class="line"></span><br><span class="line">[time, Wandering, Earth, throwback, eras, filmmaking] </span><br><span class="line"></span><br><span class="line">[film, ’s, cast, tone, Chinese, science, fiction, fans, lot, screen, movies]</span><br></pre></td></tr></table></figure><h2 id="2-以每一句为单位，获得该句子中指定窗口大小的pair，最终得到整个文本的token-pairs集合"><a href="#2-以每一句为单位，获得该句子中指定窗口大小的pair，最终得到整个文本的token-pairs集合" class="headerlink" title="2. 以每一句为单位，获得该句子中指定窗口大小的pair，最终得到整个文本的token_pairs集合"></a>2. 以每一句为单位，获得该句子中指定窗口大小的pair，最终得到整个文本的token_pairs集合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get_token_pairs</span></span><br><span class="line"></span><br><span class="line">token_pairs = []</span><br><span class="line">window_size = <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">    <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(sent):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> (i+<span class="number">1</span>, i+window_size):</span><br><span class="line">            <span class="keyword">if</span> j &gt;= len(sent):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            pair = (word, sent[j])</span><br><span class="line">            <span class="keyword">if</span> pair <span class="keyword">not</span> <span class="keyword">in</span> token_pairs:</span><br><span class="line">                token_pairs.append(pair)</span><br><span class="line">print(token_pairs)</span><br></pre></td></tr></table></figure><p>​        [output]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(Wandering, Earth), (Wandering, budget), (Earth, China), (Earth, science), (China, ’s), (China, fiction), (’s, budget), (’s, thriller), (budget, science), (budget, screens), (science, fiction), (science, AMC), (fiction, thriller), (fiction, theaters), (thriller, screens), (thriller, North), (screens, AMC), (screens, America), (AMC, theaters), (AMC, weekend), (theaters, North), (theaters, filmmaking), (North, America), (North, —), (America, weekend), (America, spectacles), (weekend, filmmaking), (weekend, China), (filmmaking, —), (filmmaking, ’s), (—, spectacles), (—, epics), (spectacles, China), (China, ’s), (’s, epics), (time, Wandering), (time, eras), (Wandering, Earth), (Wandering, filmmaking), (Earth, throwback), (throwback, eras), (eras, filmmaking), (film, ’s), (film, Chinese), (’s, cast), (’s, science), (cast, tone), (cast, fiction), (tone, Chinese), (tone, fans), (Chinese, science), (Chinese, lot), (science, fiction), (science, screen), (fiction, fans), (fiction, movies), (fans, lot), (lot, screen), (screen, movies)]</span><br></pre></td></tr></table></figure><h2 id="3-获得所有的tokens的集合，即该文本的表征词汇集合-vocab"><a href="#3-获得所有的tokens的集合，即该文本的表征词汇集合-vocab" class="headerlink" title="3. 获得所有的tokens的集合，即该文本的表征词汇集合 - vocab"></a>3. 获得所有的tokens的集合，即该文本的表征词汇集合 - vocab</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get_vocab</span></span><br><span class="line"></span><br><span class="line">vocab = OrderedDict()</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sent:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> vocab:</span><br><span class="line">            vocab[word] = i</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">print(vocab)</span><br><span class="line">len(vocab)</span><br></pre></td></tr></table></figure><p>​        [output]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(Wandering, 0), (Earth, 1), (China, 2), (’s, 3), (budget, 4), (science, 5), (fiction, 6), (thriller, 7), (screens, 8), (AMC, 9), (theaters, 10), (North, 11), (America, 12), (weekend, 13), (filmmaking, 14), (—, 15), (spectacles, 16), (China, 17), (’s, 18), (epics, 19), (time, 20), (Wandering, 21), (Earth, 22), (throwback, 23), (eras, 24), (filmmaking, 25), (film, 26), (’s, 27), (cast, 28), (tone, 29), (Chinese, 30), (science, 31), (fiction, 32), (fans, 33), (lot, 34), (screen, 35), (movies, 36)])</span><br></pre></td></tr></table></figure><h2 id="4-根据获得的vocab和token-pairs，来得到文本图的矩阵表示，并将矩阵归一化"><a href="#4-根据获得的vocab和token-pairs，来得到文本图的矩阵表示，并将矩阵归一化" class="headerlink" title="4. 根据获得的vocab和token_pairs，来得到文本图的矩阵表示，并将矩阵归一化"></a>4. 根据获得的vocab和token_pairs，来得到文本图的矩阵表示，并将矩阵归一化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get_matrix</span></span><br><span class="line"></span><br><span class="line">vocab_size = len(vocab)</span><br><span class="line">matrix_for_text = np.zeros((vocab_size, vocab_size), dtype=<span class="string">'float'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word1, word2 <span class="keyword">in</span> token_pairs:</span><br><span class="line">    i, j = vocab[word1], vocab[word2]</span><br><span class="line">    matrix_for_text[i][j] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在关键词抽取中，我们把文本看做了一个无向图，无向图的矩阵表示是一个对称矩阵，以下就是无向图矩阵的对称化</span></span><br><span class="line">matrix_for_text = matrix_for_text + matrix_for_text.T - np.diag(matrix_for_text.diagonal())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对矩阵的每一列进行求和 -- 也就是该列顶点对应的出度总和</span></span><br><span class="line">norm = np.sum(matrix_for_text, axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># normalization以后的矩阵</span></span><br><span class="line">matrix_for_text = np.divide(matrix_for_text, norm, where=(norm!=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><h2 id="5-迭代计算出每个token的weight"><a href="#5-迭代计算出每个token的weight" class="headerlink" title="5. 迭代计算出每个token的weight"></a>5. 迭代计算出每个token的weight</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># analyze()</span></span><br><span class="line"></span><br><span class="line">min_diff = <span class="number">1e-5</span></span><br><span class="line">d = <span class="number">0.85</span></span><br><span class="line">iterations = <span class="number">10</span></span><br><span class="line">tr = np.array([<span class="number">1</span>] * vocab_size)</span><br><span class="line">print(tr)</span><br><span class="line">previous_tr = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">    tr = <span class="number">1</span>-d + d*(np.dot(matrix_for_text, tr))</span><br><span class="line">    <span class="keyword">if</span> abs(previous_tr - sum(tr)) &lt; min_diff:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        previous_tr = sum(tr)</span><br><span class="line"></span><br><span class="line">print(tr)</span><br></pre></td></tr></table></figure><p>​        [output]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[0.72611111 0.91529514 0.92414931 0.91352431 1.10772569 1.16616319</span><br><span class="line"> 1.08086806 1.04574653 1.0903125  1.03010417 1.03010417 1.0903125</span><br><span class="line"> 1.04574653 1.08086806 1.16616319 1.10772569 0.91352431 0.92414931</span><br><span class="line"> 0.91529514 0.72611111 0.9575     1.12395833 0.91854167 0.91854167</span><br><span class="line"> 1.12395833 0.9575     0.74116319 0.93034722 1.00442708 0.96428819</span><br><span class="line"> 1.19361111 1.33232639 1.19361111 0.96428819 1.00442708 0.93034722</span><br><span class="line"> 0.74116319]</span><br></pre></td></tr></table></figure><h2 id="6-对权值进行排序"><a href="#6-对权值进行排序" class="headerlink" title="6. 对权值进行排序"></a>6. 对权值进行排序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get_keywords()</span></span><br><span class="line"></span><br><span class="line">node_weight = dict()</span><br><span class="line"><span class="keyword">for</span> word, index <span class="keyword">in</span> vocab.items():</span><br><span class="line">    node_weight[word] = tr[index]</span><br><span class="line"></span><br><span class="line">node_weight_ordered = OrderedDict(sorted(node_weight.items(), key=<span class="keyword">lambda</span> t:t[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> node_weight_ordered.items():</span><br><span class="line">    print(k, <span class="string">" -- "</span>, v)</span><br></pre></td></tr></table></figure><p>​        [output]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">science  --  1.3323263888888888</span><br><span class="line">Chinese  --  1.1936111111111112</span><br><span class="line">fiction  --  1.1936111111111112</span><br><span class="line">science  --  1.1661631944444442</span><br><span class="line">filmmaking  --  1.1661631944444442</span><br><span class="line">Wandering  --  1.1239583333333334</span><br><span class="line">eras  --  1.1239583333333334</span><br><span class="line">budget  --  1.1077256944444445</span><br><span class="line">—  --  1.1077256944444445</span><br><span class="line">screens  --  1.0903125</span><br><span class="line">North  --  1.0903125</span><br><span class="line">fiction  --  1.0808680555555554</span><br><span class="line">weekend  --  1.0808680555555554</span><br><span class="line">thriller  --  1.0457465277777778</span><br><span class="line">America  --  1.0457465277777778</span><br><span class="line">AMC  --  1.0301041666666666</span><br><span class="line">theaters  --  1.0301041666666666</span><br><span class="line">cast  --  1.004427083333333</span><br><span class="line">lot  --  1.004427083333333</span><br><span class="line">tone  --  0.9642881944444444</span><br><span class="line">fans  --  0.9642881944444444</span><br><span class="line">time  --  0.9574999999999999</span><br><span class="line">filmmaking  --  0.9574999999999999</span><br><span class="line">screen  --  0.9303472222222222</span><br><span class="line">’s  --  0.9303472222222221</span><br><span class="line">China  --  0.9241493055555555</span><br><span class="line">China  --  0.9241493055555555</span><br><span class="line">Earth  --  0.9185416666666666</span><br><span class="line">throwback  --  0.9185416666666666</span><br><span class="line">Earth  --  0.9152951388888888</span><br><span class="line">’s  --  0.9152951388888888</span><br><span class="line">’s  --  0.9135243055555555</span><br><span class="line">spectacles  --  0.9135243055555555</span><br><span class="line">film  --  0.7411631944444443</span><br><span class="line">movies  --  0.7411631944444443</span><br><span class="line">Wandering  --  0.726111111111111</span><br><span class="line">epics  --  0.726111111111111</span><br></pre></td></tr></table></figure><p>具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> spacy.lang.en.stop_words <span class="keyword">import</span> STOP_WORDS</span><br><span class="line"></span><br><span class="line">nlp = spacy.load(<span class="string">"en_core_web_sm"</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KeywordExtraction</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.d = <span class="number">0.85</span>         <span class="comment"># damping factor</span></span><br><span class="line">        self.min_diff = <span class="number">1e-5</span>  <span class="comment"># </span></span><br><span class="line">        self.steps = <span class="number">10</span>       <span class="comment"># iterate steps</span></span><br><span class="line">        self.node_weight = <span class="literal">None</span>  <span class="comment"># node_weight</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_stopwords</span><span class="params">(self, stopwords)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        添加自定义 stop_words</span></span><br><span class="line"><span class="string">        :param stopwords:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> STOP_WORDS.union(set(stopwords)):</span><br><span class="line">            lexeme = nlp.vocab[word]</span><br><span class="line">            lexeme.is_stop = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sentence_segment</span><span class="params">(self, doc, candidate_pos, lower=False)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        保存每一句中特定词性的单词</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line"></span><br><span class="line">        sentences = []</span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> doc.sents:</span><br><span class="line">            selected_words = []</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> sent:</span><br><span class="line">                <span class="keyword">if</span> word.pos_ <span class="keyword">in</span> candidate_pos <span class="keyword">and</span> word.is_stop <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">                    <span class="keyword">if</span> lower:</span><br><span class="line">                        selected_words.append(word.text.lower())</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        selected_words.append(word.text)</span><br><span class="line">            sentences.append(selected_words)</span><br><span class="line">        <span class="keyword">return</span> sentences</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_vocab</span><span class="params">(self, sentences)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        得到所有句子中特定词性的单词</span></span><br><span class="line"><span class="string">        :param sentences:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        vocab = OrderedDict()</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> sent:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> vocab:</span><br><span class="line">                    vocab[word] = i</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> vocab</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_token_pairs</span><span class="params">(self, window_size, sentences)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param window_size:</span></span><br><span class="line"><span class="string">        :param sentences:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        token_pairs = []</span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">            <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(sent):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, i+window_size):</span><br><span class="line">                    <span class="keyword">if</span> j &gt;= len(sent):</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    pair = (word, sent[j])</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> pair <span class="keyword">not</span> <span class="keyword">in</span> token_pairs:</span><br><span class="line">                        token_pairs.append(pair)</span><br><span class="line">        <span class="keyword">return</span> token_pairs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">symmetrize</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> matrix + matrix.T - np.diag(matrix.diagonal())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_matrix</span><span class="params">(self, vocab, token_pairs)</span>:</span></span><br><span class="line">        vocab_size = len(vocab)</span><br><span class="line"></span><br><span class="line">        g = np.zeros((vocab_size, vocab_size), dtype=<span class="string">'float'</span>)</span><br><span class="line">        <span class="keyword">for</span> word1, word2 <span class="keyword">in</span> token_pairs:</span><br><span class="line">            i, j = vocab[word1], vocab[word2]</span><br><span class="line">            g[i][j] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        g = self.symmetrize(g)</span><br><span class="line"></span><br><span class="line">        sum = np.sum(g, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        np.divide(x1, x2, where=True)</span></span><br><span class="line"><span class="string">        x1: array_like 被除矩阵</span></span><br><span class="line"><span class="string">        x2: array_like 除数矩阵</span></span><br><span class="line"><span class="string">        如果x1和x2的shape不一致的话，他们必须符合数组广播规则，也就是输出矩阵的shape</span></span><br><span class="line"><span class="string">        -- 换言之，输入数组必须具有相同的形状或符合数组广播规则</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        g_after_divide = np.divide(g, sum, where=sum!=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> g_after_divide</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_keywords</span><span class="params">(self, num=<span class="number">10</span>)</span>:</span></span><br><span class="line">        node_weight = OrderedDict(sorted(self.node_weight.items(), key= <span class="keyword">lambda</span> t: t[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, (k, v) <span class="keyword">in</span> enumerate(node_weight.items()):</span><br><span class="line">            print(k, <span class="string">" -- "</span>, v)</span><br><span class="line">            <span class="keyword">if</span> i &gt; num:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">analyze</span><span class="params">(self, doc, window_size=<span class="number">4</span>, candidate_pos=[<span class="string">'NOUN'</span>, <span class="string">'PROPN'</span>],</span></span></span><br><span class="line"><span class="function"><span class="params">                lower=False, stopwords=list<span class="params">()</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.set_stopwords(stopwords)</span><br><span class="line">        doc_sentences = self.sentence_segment(doc, candidate_pos, lower)</span><br><span class="line">        doc_vocab = self.get_vocab(doc_sentences)</span><br><span class="line">        doc_token_pairs = self.get_token_pairs(window_size, doc_sentences)</span><br><span class="line">        doc_matrix = self.get_matrix(doc_vocab, doc_token_pairs)</span><br><span class="line"></span><br><span class="line">        vocab_size = len(doc_vocab)</span><br><span class="line">        tr = np.array([<span class="number">1</span>] * vocab_size)</span><br><span class="line">        previous_tr = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.steps):</span><br><span class="line">            tr = <span class="number">1</span>-self.d + self.d * np.dot(doc_matrix, tr)</span><br><span class="line">            <span class="keyword">if</span> abs(previous_tr - sum(tr)) &lt; self.min_diff:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            previous_tr = sum(tr)</span><br><span class="line"></span><br><span class="line">        node_weight = dict()</span><br><span class="line">        <span class="keyword">for</span> word, index <span class="keyword">in</span> doc_vocab.items():</span><br><span class="line">            node_weight[word] = tr[index]</span><br><span class="line"></span><br><span class="line">        self.node_weight = node_weight</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    textrank = KeywordExtraction()</span><br><span class="line">    text = <span class="string">'''</span></span><br><span class="line"><span class="string">       The Wandering Earth, described as China’s first big-budget science fiction thriller, quietly made it onto screens at AMC theaters in North America this weekend, and it shows a new side of Chinese filmmaking — one focused toward futuristic spectacles rather than China’s traditionally grand, massive historical epics. At the same time, The Wandering Earth feels like a throwback to a few familiar eras of American filmmaking. While the film’s cast, setting, and tone are all Chinese, longtime science fiction fans are going to see a lot on the screen that reminds them of other movies, for better or worse.</span></span><br><span class="line"><span class="string">       '''</span></span><br><span class="line">    doc = nlp(text)</span><br><span class="line">    textrank.analyze(doc, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># 取前10个权值最高的单词</span></span><br><span class="line">    textrank.get_keywords(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Keyword-Extraction-by-TextRank&quot;&gt;&lt;a href=&quot;#Keyword-Extraction-by-TextRank&quot; class=&quot;headerlink&quot; title=&quot;Keyword Extraction by TextRank&quot;&gt;
      
    
    </summary>
    
      <category term="TextRank" scheme="http://yoursite.com/categories/TextRank/"/>
    
    
  </entry>
  
  <entry>
    <title>Python正则表达式-不完全使用指南</title>
    <link href="http://yoursite.com/2019/07/22/Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E4%B8%8D%E5%AE%8C%E5%85%A8%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://yoursite.com/2019/07/22/Python正则表达式-不完全使用指南/</id>
    <published>2019-07-22T12:39:52.000Z</published>
    <updated>2019-08-01T03:23:01.027Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-基础字符"><a href="#1-基础字符" class="headerlink" title="1. 基础字符"></a>1. 基础字符</h1><h2 id="1-1-元字符"><a href="#1-1-元字符" class="headerlink" title="1.1 元字符"></a>1.1 元字符</h2><p>元字符是一些特殊的metacharactes， 并且不匹配自己。相反，他们表示应该匹配一些与众不同的东西，或者通过重复他们或改变他们的含义来影响正则的其他部分。元字符如下：</p><blockquote><p>.  ^  $  *  +  ?  {  }  [  ]  \  |  (  )</p></blockquote><ol><li>在元字符”[ ]”中，可以单独列出字符，也可以通过给出两个字符并用”-“标记将它们分开来表示一系列字符。例如，[abc]将匹配任何字符a、b或c（匹配单个字符），这与[a-c]相同，它使用一个范围来表示同一组字符。</li><li>字符类中的元字符不生效。例如，[akm$]将匹配’a’, ‘k’, ‘m’, ‘$’中的任意字符; ‘$’通常是一个元字符，但在一个字符类中它被剥夺了特殊性。</li></ol><h2 id="1-2-预定义字符集"><a href="#1-2-预定义字符集" class="headerlink" title="1.2 预定义字符集"></a>1.2 预定义字符集</h2><ul><li><code>\d</code> 匹配任何十进制数字；这等价于<code>[0-9]</code></li><li><code>\D</code> 匹配任何非数字字符；这等价于<code>[^0-9]</code></li><li><code>\s</code> 匹配任何空白字符；这等价于<code>[ \t\n\r\f\v]</code> </li><li><code>\S</code> 匹配任何非空白字符；这等价于<code>[^ \t\n\r\f\v]</code></li><li><code>\w</code> 匹配任何字母与数字字符；这相当于类<code>[a-zA-Z0-9]</code></li><li><code>\W</code> 匹配任何非字母与数字字符；这相当于类<code>[^a-zA-Z0-9]</code></li></ul><h2 id="1-3-常用操作符"><a href="#1-3-常用操作符" class="headerlink" title="1.3 常用操作符"></a>1.3 常用操作符</h2><div class="table-container"><table><thead><tr><th>操作符</th><th>说明</th><th>实例</th></tr></thead><tbody><tr><td>.</td><td>表示任意单个字符</td><td>对于大小写字母、各种符号都能匹配</td></tr><tr><td>[  ]</td><td>字符集，对单个字符给出取值范围</td><td>[abc]表示a、b、c,[a-z]表示a到z的单个字符</td></tr><tr><td><sup><a href="#fn_  " id="reffn_  ">  </a></sup></td><td>非字符集，对单个字符给出排除范围</td><td><sup><a href="#fn_abc " id="reffn_abc ">abc </a></sup>表示非a或b或c的单个字符</td></tr><tr><td>*</td><td>前一个字符0次或无限次扩展</td><td>abc*表示ab、abc、abcc、abccc等</td></tr><tr><td>+</td><td>前一个字符1次或无限次扩展</td><td>abc+表示abc、abcc、abccc等</td></tr><tr><td>？</td><td>前一个字符0次或1次扩展</td><td>abc？表示ab、abc</td></tr><tr><td>\</td><td></td><td>左右表达式任意一个</td><td>abc\</td><td>def表示abc、def</td></tr><tr><td>{m}</td><td>扩展前一个字符m次</td><td>ab{2}c表示abbc</td></tr><tr><td>{m, n}</td><td>扩展前一个字符m至n次（包  含n）</td><td>ab{1, 2}表示ab、abb</td></tr><tr><td>^</td><td>匹配字符串开头</td><td>^abc表示abc且在一个字符串的开头</td></tr><tr><td>$</td><td>匹配字符串结尾</td><td>abc$表示abc且在一个字符串的结尾</td></tr><tr><td>( )</td><td>分组标记，内部只能使用 \</td><td>操作符</td><td>(abc)表示abc，(abc \</td><td>def)表示abc、def</td></tr><tr><td>\d</td><td>表示十进制数字</td><td></td></tr><tr><td>\w</td><td>匹配任何字母与数字字符</td><td>相当于[a-zA-Z0-9]</td></tr></tbody></table></div><blockquote><p>tips:</p><ol><li>?字符可以看作是一个可选字符，如home-?grew，其表示home-grew或者homegrew，即当作 ? 的前一个字符是可选的的；</li><li>对于{m, n}来说，如果不限定m和n的数值，即{ , }，则认为下限m的值为0，而上限n的值则为无穷，因此：<ul><li>*也就等价于{0, }</li><li>+也就等价于{1, }</li><li>?也就等价于{0, 1}</li><li>但在实际中，还是建议使用*、+、?的形式，这样更短更容易阅读</li></ul></li></ol></blockquote><h1 id="2-使用正则表达式"><a href="#2-使用正则表达式" class="headerlink" title="2. 使用正则表达式"></a>2. 使用正则表达式</h1><p>有了前面的基础字符知识，我们已经可以使用正则表达式了，在python中如何使用它们呢？re模块提供了正则表达式引擎的接口，允许你将正则编译为对象，然后用它们进行匹配。</p><h2 id="2-1-编译正则表达式"><a href="#2-1-编译正则表达式" class="headerlink" title="2.1 编译正则表达式"></a>2.1 编译正则表达式</h2><p>正则表达式首先要编译成模式对象，然后才能进行各种操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">re_pattern = re.compile(<span class="string">'ab*'</span>)</span><br><span class="line">print(<span class="string">"re_pattern : "</span>,re_pattern)</span><br><span class="line">print(<span class="string">"type :"</span>, type(re_pattern))</span><br><span class="line"></span><br><span class="line">[output]</span><br><span class="line">re_pattern :  re.compile(<span class="string">'ab*'</span>)</span><br><span class="line">type : &lt;<span class="class"><span class="keyword">class</span> '<span class="title">re</span>.<span class="title">Pattern</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>需要明确的是，正则是作为字符串传递给re.compile()的，正则被处理为字符串，因为正则表达式不是核心python语言的一部分，并且没有创建用于表达它们的特殊语法。</p><p>可以理解的是，在正则被re模块编译之前，它就是一个普通的字符串，这与python语言所理解的字符串并无二致，如前所述，正则表达式使用反斜杠字符 \ 来表示特殊形式或允许使用特殊字符而不调用它们的特殊含义，这就会与python字符串中的反斜杠用途发生冲突，导致反斜杠灾难。</p><blockquote><p>例如我们要编写一个与 \expression相匹配的正则，那么编译之后得到的目标模式就应该是  \ \expression，在编译之前，正则就是一个普通的字符串，对于每一个 \，在字符串中表示就是 \ \，也就是说，编译前的字符串就应该是 \ \ \ \ expression，可见，对目标字符串中如果有一个反斜杠，那么传给编译器的正则表达式中就会有4个反斜杠，十分繁琐。</p><div class="table-container"><table><thead><tr><th>字符</th><th>阶段</th></tr></thead><tbody><tr><td>\expression</td><td>被匹配的字符串</td></tr><tr><td>\ \ expression</td><td>为 re.compile()转义的反斜杠</td></tr><tr><td>“\\\\expression”</td><td>为字符串字面转义的反斜杠</td></tr></tbody></table></div><p>解决方案是使用python的原始字符串表示法来表示正则表达式；反斜杠不以任何特殊的方式处理前缀为 ‘r’的字符串字面，因此 r’\n’ 是一个包含 ‘\’和 ‘n’的双字符字符串，而 ‘\n’是一个包含换行符的单字符字符串。正则表达式通常使用这种原始字符串表示法用python代码编写。</p><div class="table-container"><table><thead><tr><th>常规字符串</th><th>原始字符串</th></tr></thead><tbody><tr><td>“ab*”</td><td>r”ab*”</td></tr><tr><td>“\\\\expression”</td><td>r”\\expression”</td></tr><tr><td>“\\w+\\s+\\l”</td><td>r”\w+\s+\l”</td></tr></tbody></table></div><p>tips:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="comment"># 带反斜杠的特殊字符可以用\d或者\\d来匹配</span></span><br><span class="line">&gt; pattern = re.compile(<span class="string">"\\d"</span>)</span><br><span class="line">&gt; result = pattern.findall(<span class="string">"space hh99"</span>)</span><br><span class="line">&gt; print(result)</span><br><span class="line">&gt; </span><br><span class="line">&gt; [output] : [<span class="string">'9'</span>, <span class="string">'9'</span>]</span><br><span class="line">&gt; </span><br><span class="line">&gt; <span class="comment"># 匹配一个反斜杠</span></span><br><span class="line">&gt; pattern = re.compile(<span class="string">"\\\\"</span>)</span><br><span class="line">&gt; result = pattern.findall(<span class="string">"n\\b\\a"</span>)</span><br><span class="line">&gt; print(result)</span><br><span class="line">&gt; </span><br><span class="line">&gt; [output] : [<span class="string">'\\'</span>, <span class="string">'\\'</span>]</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote></blockquote><h1 id="3-应用匹配"><a href="#3-应用匹配" class="headerlink" title="3. 应用匹配"></a>3. 应用匹配</h1><h2 id="3-1-re库的常用函数"><a href="#3-1-re库的常用函数" class="headerlink" title="3.1 re库的常用函数"></a>3.1 re库的常用函数</h2><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>search()</td><td>扫描字符串，查找此正则匹配的任何位置，返回match对象</td></tr><tr><td>match()</td><td>从一个字符串的开始位置其匹配正则表达式，返回match对象</td></tr><tr><td>findall()</td><td>搜索字符串，以列表类型返回全部能匹配的子串</td></tr><tr><td>split()</td><td>将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</td></tr><tr><td>finditer()</td><td>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象</td></tr><tr><td>sub()</td><td>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td></tr></tbody></table></div><h2 id="3-2-匹配对象"><a href="#3-2-匹配对象" class="headerlink" title="3.2 匹配对象"></a>3.2 匹配对象</h2><div class="table-container"><table><thead><tr><th>方法/属性</th><th>目的</th></tr></thead><tbody><tr><td>group()</td><td>返回正则匹配的字符串</td></tr><tr><td>start()</td><td>返回匹配的开始位置</td></tr><tr><td>end()</td><td>返回匹配的结束位置</td></tr><tr><td>span()</td><td>返回包含匹配(start, end)位置的元组</td></tr></tbody></table></div><p>group()返回正则匹配的子字符串。start()和end()返回匹配的其实和结束索引。span()在单个元组中返回开始和结束索引。由于match()方法只检查正则是否在字符串的开头匹配，所以start()将始终为0。</p><blockquote><p>注意：</p><p>只有match对象才有上述属性，也就是说，对一个模式只有使用search()、match()和finditer()后所返回的match对象才有上述属性，而对于使用findall()等方法，由于其返回对象是一个list，所以没有上述属性。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">result1 = pattern.match(<span class="string">"little boy found his favorite toy"</span>)</span><br><span class="line">result2 = pattern.match(<span class="string">"littleboyfoundhisfavoritetoy"</span>)</span><br><span class="line">print(result1)</span><br><span class="line">print(result2)</span><br><span class="line"></span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>&lt;re.Match object; span=(<span class="number">0</span>, <span class="number">6</span>), match=<span class="string">'little'</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>&lt;re.Match object; span=(<span class="number">0</span>, <span class="number">28</span>),        match=<span class="string">'littleboyfoundhisfavoritetoy'</span>&gt;</span><br><span class="line"></span><br><span class="line">result2.group()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'littleboyfoundhisfavoritetoy'</span></span><br><span class="line"></span><br><span class="line">result2.start()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0</span></span><br><span class="line"></span><br><span class="line">result2.end()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">28</span></span><br><span class="line"></span><br><span class="line">result2.span()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(<span class="number">0</span>, <span class="number">28</span>)</span><br></pre></td></tr></table></figure><p>但是，模式的search()方法会扫描字符串，因此在这种情况下匹配可能不会从0开始。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">result3 = pattern.search(<span class="string">"****little boy`s here"</span>)</span><br><span class="line">result3.group()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'little'</span></span><br><span class="line"></span><br><span class="line">result3.start()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">4</span></span><br><span class="line"></span><br><span class="line">result3.end()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">10</span></span><br><span class="line"></span><br><span class="line">result3.span()</span><br><span class="line">[output]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(<span class="number">4</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><h1 id="4-更多模式能力"><a href="#4-更多模式能力" class="headerlink" title="4. 更多模式能力"></a>4. 更多模式能力</h1><h2 id="4-1-分组"><a href="#4-1-分组" class="headerlink" title="4.1 分组"></a>4.1 分组</h2><p>通常，你需要获取更多信息，而不仅仅是正则是否匹配。正则表达式通常用于通过将正则分成几个子组来解析字符串，这些子组匹配不同的感兴趣组件。</p><p>例如，现有如下信息：</p><blockquote><p>From: author@example.com</p><p>User-Agent: Thunderbird</p><p>MIME-Version: 1.0</p><p>To: editor@example</p></blockquote><p>我们想要提取每一个 ：后面的信息，因此可以使用分组来进行匹配，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e.g. 4.1.1</span></span><br><span class="line"></span><br><span class="line">info = <span class="string">"From: author@example.com\nUser-Agent: Thunderbird\nMIME-Version: 1.0\nTo: editor@example"</span></span><br><span class="line"></span><br><span class="line">print(info)</span><br><span class="line">[output]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">From: author@example.com</span><br><span class="line">User-Agent: Thunderbird</span><br><span class="line">MIME-Version: <span class="number">1.0</span></span><br><span class="line">To: editor@example</span><br><span class="line"></span><br><span class="line">pattern1 = re.compile(<span class="string">r"From:\s+(\w+.\w+.\w+)\s+User-Agent:\s+(\w+)\s+MIME-Version:\s+(\d+.\d+)\s+To:\s+(\w+.\w+)"</span>, re.IGNORECASE)</span><br><span class="line"></span><br><span class="line">result = pattern1.findall(info)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line">[output]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[(<span class="string">'author@example.com'</span>, <span class="string">'Thunderbird'</span>, <span class="string">'1.0'</span>, <span class="string">'editor@example'</span>)]</span><br><span class="line"></span><br><span class="line">result1 = pattern1.finditer(info)</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> result1:</span><br><span class="line">    result.group(<span class="number">1</span>)</span><br><span class="line">    result.group(<span class="number">2</span>)</span><br><span class="line">    result.group(<span class="number">3</span>)</span><br><span class="line">    result.group(<span class="number">4</span>)</span><br><span class="line">   </span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">'author@example.com'</span></span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">'Thunderbird'</span></span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">'1.0'</span></span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">'editor@example'</span></span><br></pre></td></tr></table></figure><p>再上述4.1.1的例子中，我们在模式中写了四个分组，分别匹配From、User-Agent、MIME-Version和To后面的内容，这四个分组被自动地编号，分别为1、2、3、4，同时被捕获到了相应的内存中，这就引入了分组的后向引用，例如，我要进行一个双词的匹配，请看下例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#e.g. 4.1.2</span></span><br><span class="line"></span><br><span class="line">raw = <span class="string">"loving loving can hurt"</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">在匹配之前，(\w+)这个分组可以匹配任何单词内容，一旦当这个分组匹配完毕，在这里，一开始就匹配了loving这个单词，因此，就把loving捕获，放在分组1的内存单元，再经过一个空格后，把分组1中的捕获内容取出，与当前单词比较，看是否匹配，如果匹配，则结束，否则，重新匹配这个分组。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">pattern = re.compile(<span class="string">r"\b(\w+)\b\s+\1"</span>)</span><br><span class="line">print(pattern.findall(raw))</span><br><span class="line"></span><br><span class="line">[output]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="string">'loving'</span>]</span><br></pre></td></tr></table></figure><h2 id="4-2-忽略某个分组"><a href="#4-2-忽略某个分组" class="headerlink" title="4.2 忽略某个分组"></a>4.2 忽略某个分组</h2><p>有时候给正则的某个子表达式加括号并不是为了分组，而仅仅是为了看起来更清晰，因此我们并不需要捕获该分组，那么，可以使用(?:expression)来忽略该分组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e.g. 4.2.1</span></span><br><span class="line">raw = <span class="string">"age:13, name:Tom"</span></span><br><span class="line">pattern = re.compile(<span class="string">r"age.(\d+).\s*name.(\w+)"</span>)</span><br><span class="line"></span><br><span class="line">print(pattern.findall(raw))</span><br><span class="line">[out]: [(<span class="string">'13'</span>, <span class="string">'Tom'</span>)]</span><br><span class="line"></span><br><span class="line">print(pattern.search(raw).group(<span class="number">1</span>))</span><br><span class="line">[out]: <span class="number">13</span></span><br><span class="line">    </span><br><span class="line">print(pattern.search(raw).group(<span class="number">2</span>))</span><br><span class="line">[out]: Tom</span><br><span class="line">    </span><br><span class="line">pattern1 = re.compile(<span class="string">r"age.(\d+).\s*name.(?:\w+)"</span>)</span><br><span class="line">print(pattern1.findall(raw))</span><br><span class="line">[out]: [<span class="string">'13'</span>]</span><br><span class="line">print(pattern1.search(raw).group(<span class="number">1</span>))</span><br><span class="line">[out]: <span class="number">13</span></span><br><span class="line"><span class="comment"># 由于忽略了第二个分组，因此无法检索该分组</span></span><br><span class="line">print(pattern1.search(raw).group(<span class="number">2</span>))</span><br><span class="line">[out]: IndexError: no such group</span><br></pre></td></tr></table></figure><p>需要注意的是，除了你无法检索组匹配内容的事实外，非捕获组的行为与捕获组完全相同；你可以在里面放任何东西，用重复元字符重复它，比如*，燃火把它嵌入其他组（捕获或不捕获）。<font color="red">(?:…..)在修改现有模式的时候特别有用，因为你可以添加新组而不更改所有其他组的编号方式。</font><font color="blue">红色部分不懂什么意思。</font>值得一提的是，捕获和非捕获组之间的搜索没有性能差异，两种形式没有哪一种更快。</p><h2 id="4-3-命名分组"><a href="#4-3-命名分组" class="headerlink" title="4.3 命名分组"></a>4.3 命名分组</h2><p>命名组的语法是python特定的扩展之一：(?P<name>…)。name是该分组的名称。命名组的行为与捕获组完全相同，并且还将名称与组关联。处理捕获组的的匹配对象方法都接受 1. 按编号引用该分组；2. 按组名字符串引用该分组。</name></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">raw = <span class="string">"sheeran sheeran is good"</span></span><br><span class="line">pattern = re.compile(<span class="string">r"(?P&lt;name&gt;\b\w+\b)\s+(?P=name)"</span>)</span><br><span class="line">print(pattern.findall(raw))</span><br><span class="line"></span><br><span class="line">[out]: [<span class="string">'sheeran'</span>]</span><br><span class="line"></span><br><span class="line">pattern = re.compile(<span class="string">r"(?P&lt;name&gt;\b\w+\b)\s+\1"</span>)</span><br><span class="line">print(pattern.findall(raw))</span><br><span class="line"></span><br><span class="line">[out]: [<span class="string">'sheeran'</span>]</span><br></pre></td></tr></table></figure><h2 id="4-4-前向断言"><a href="#4-4-前向断言" class="headerlink" title="4.4 前向断言"></a>4.4 前向断言</h2><p>另一个零宽度断言是前向断言。前向断言以正面和负面形式提供，如下所示：</p><ol><li><h4 id="正前向断言-—-…"><a href="#正前向断言-—-…" class="headerlink" title="正前向断言  —  (?=…)"></a>正前向断言  —  (?=…)</h4><p>如果包含的正则表达式，由<code>...</code>表示，在当前位置成功匹配，则成功，否则失败。但是，一旦尝试了包含的表达式，匹配的引擎就不会前进，模式其余的部分会在断言开始的地方尝试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选出得分大于30分的球员</span></span><br><span class="line">raw = [<span class="string">"James:36.33"</span>, <span class="string">"Bryant:33.2"</span>, <span class="string">"ONeal:24.33"</span>]</span><br><span class="line">pattern = re.compile(<span class="string">r".+(?=[:][3][0-9][.][0-9]+)"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> raw:</span><br><span class="line">    print(pattern.findall(it))</span><br><span class="line">    </span><br><span class="line">[out]: [<span class="string">'James'</span>]</span><br><span class="line">   [<span class="string">'Bryant'</span>]</span><br><span class="line">   []</span><br></pre></td></tr></table></figure></li></ol><ol><li><h4 id="负前向断言-—-…"><a href="#负前向断言-—-…" class="headerlink" title="负前向断言  —  (?!…)"></a>负前向断言  —  (?!…)</h4><p>如果包含的表达式在字符串中的当前位置不匹配，则成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">现有一些文件如下：</span></span><br><span class="line"><span class="string">["sample.txt", "ss.batch", "text.bat", "computer.sss", "name.is.wiki", "haha.bat.ten", "start.end.bat"]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">我们需要从中选取出后缀不是bat的文件，因此可以使用负前向断言来匹配后缀不是bat的文件</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">raw = [<span class="string">"sample.txt"</span>, <span class="string">"ss.batch"</span>, <span class="string">"text.bat"</span>, <span class="string">"computer.sss"</span>, <span class="string">"name.is.wiki"</span>, <span class="string">"haha.bat.ten"</span>, <span class="string">"start.end.bat"</span>]</span><br><span class="line"></span><br><span class="line">pattern = re.compile(<span class="string">r".*[.](?!bat$)[^.]*"</span>)</span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> raw:</span><br><span class="line">    print(pattern.findall(it))</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">[out]: [<span class="string">'sample.txt'</span>]</span><br><span class="line">   [<span class="string">'ss.batch'</span>]</span><br><span class="line">       []</span><br><span class="line">       [<span class="string">'computer.sss'</span>]</span><br><span class="line">       [<span class="string">'name.is.wiki'</span>]</span><br><span class="line">       [<span class="string">'haha.bat.ten'</span>]</span><br><span class="line">       []</span><br></pre></td></tr></table></figure><p>在上述代码中，模式是<code>r&quot;.*[.](?!bat$)[^.]*&quot;</code>，意思是，从结尾匹配bat，如果匹配，则该模式失败，如果结尾不匹配bat，那么开始匹配模式<code>[^.]*$</code>。也就是说，如果结尾不匹配bat，我们使用<code>[^.]*$</code> 就可以把不匹配的后缀部分输出。如果我们使用的模式是<code>r&quot;.*[.](?!bat$)</code>，那么就相当于把后缀不是bat的<code>.*[.]</code> 输出，即只是输出后缀前面的部分:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">raw = [<span class="string">"sample.txt"</span>, <span class="string">"ss.batch"</span>, <span class="string">"text.bat"</span>, <span class="string">"computer.sss"</span>, <span class="string">"name.is.wiki"</span>, <span class="string">"haha.bat.ten"</span>]</span><br><span class="line"></span><br><span class="line">pattern = re.compile(<span class="string">r".*[.](?!bat$)"</span>)</span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> raw:</span><br><span class="line">    print(pattern.findall(it))</span><br><span class="line">    </span><br><span class="line">[out]: [<span class="string">'sample.'</span>]</span><br><span class="line">   [<span class="string">'ss.'</span>]</span><br><span class="line">   []</span><br><span class="line">   [<span class="string">'computer.'</span>]</span><br><span class="line">   [<span class="string">'name.is.'</span>]</span><br><span class="line">   [<span class="string">'haha.bat.'</span>]</span><br></pre></td></tr></table></figure><blockquote><p>tips:</p><p>在平常使用中，更感觉前向断言像是一个筛选条件，我们可以匹配一个字符或字符串，在匹配对象的后面或者前面我们设定一些条件，可以用前向断言来实现。</p></blockquote></li></ol><h1 id="5-修改字符串"><a href="#5-修改字符串" class="headerlink" title="5. 修改字符串"></a>5. 修改字符串</h1><p>到目前为止，我们只是针对静态字符串执行搜索。正则表达式通常也用于以各种方式修改字符串，使用以下模式方法：</p><div class="table-container"><table><thead><tr><th>方法/属性</th><th>目的</th></tr></thead><tbody><tr><td>split()</td><td>将字符串拆分成一个列表，在正则匹配的任何地方将其拆分</td></tr><tr><td>sub()</td><td>找到正则匹配的所有子字符串，并用不同的字符串替换它们</td></tr><tr><td>subn()</td><td>与sub()相同，但返回新字符串和替换次数</td></tr></tbody></table></div><h2 id="5-1-分割字符串"><a href="#5-1-分割字符串" class="headerlink" title="5.1 分割字符串"></a>5.1 分割字符串</h2><p>模式的split()方法在正则匹配的任何地方拆分字符串，返回一个片段列表。它有两种使用方式：</p><ul><li><code>pattern.split(string [, maxsplit = 0])</code></li><li><code>re.split(pattern, string [, maxsplit = 0])</code></li></ul><p>通过正则表达式的匹配拆分字符串，如果在正则中使用捕获括号，则它们的内容也将作为结果列表的一部分返回。如果maxsplit非零，则最多执行maxsplit次拆分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分隔符是任意非字母数字字符序列</span></span><br><span class="line">p = re.compile(<span class="string">r"\W+"</span>)</span><br><span class="line"><span class="comment"># 不设定maxsplit</span></span><br><span class="line">result1 = p.split(<span class="string">"this is a test, short and sweet, of split()"</span>)</span><br><span class="line">print(result1)</span><br><span class="line"></span><br><span class="line">[out]:  [<span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'a'</span>, <span class="string">'test'</span>, <span class="string">'short'</span>, <span class="string">'and'</span>, <span class="string">'sweet'</span>, <span class="string">'of'</span>, <span class="string">'split'</span>, <span class="string">''</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定maxsplit = 3，则最多在字符串上分隔3次</span></span><br><span class="line">result2 = p.split(<span class="string">"this is a test, short and sweet, of split()"</span>, maxsplit = <span class="number">3</span>)</span><br><span class="line">print(result2)</span><br><span class="line"></span><br><span class="line">[out]:  [<span class="string">'this'</span>, <span class="string">'is'</span>, <span class="string">'a'</span>, <span class="string">'test, short and sweet, of split()'</span>]</span><br></pre></td></tr></table></figure><p>如果我们不单单想要根据分隔符分隔出的文本，而且还需要知道分隔符是什么，因此，如果在正则中使用捕获括号，则分隔符的内容也会作为列表的一部分返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在这一句中，分隔符是“， ”</span></span><br><span class="line">re.split(<span class="string">r"([\W]+)"</span>, <span class="string">"words, words, words"</span>)</span><br></pre></td></tr></table></figure><h2 id="5-2-搜索和替换"><a href="#5-2-搜索和替换" class="headerlink" title="5.2 搜索和替换"></a>5.2 搜索和替换</h2><p>另一个常见任务是找到模式的所有匹配项，并用不同的字符串替换它们。sub()方法接受一个替换值，可以是字符串或函数，也可以是要处理的字符串。</p><ul><li><code>pattern.sub(replacement, string[, count = 0])</code></li></ul><ol><li>使用replacement来替换string中的匹配对象，如果没有找到模式，则string将保持不变。</li><li>可选参数count是要替换的模式最大出现次数，count必须是非负整数。默认为0表示替换所有。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">raw = <span class="string">"sheeran is a good singer, and I think sheeran is awesome!"</span></span><br><span class="line">pattern = re.compile(<span class="string">r"sheeran"</span>)</span><br><span class="line">pattern.sub(<span class="string">"jay"</span>, raw)</span><br><span class="line"></span><br><span class="line">[out]:  </span><br><span class="line"><span class="string">'jay is a good singer, and I think jay is awesome!'</span></span><br><span class="line"></span><br><span class="line">pattern.sub(<span class="string">"Jay"</span>, raw, count = <span class="number">1</span>)</span><br><span class="line">[out]:</span><br><span class="line">    <span class="string">'Jay is a good singer, and I think sheeran is awesome!'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># subn的用法和sub一致，但返回一个包含新字符串值和一致性的替换次数的2元组。    </span></span><br><span class="line">pattern.subn(<span class="string">"Jay"</span>, raw)</span><br><span class="line">[out]:</span><br><span class="line">    (<span class="string">'Jay is a good singer, and I think Jay is awesome!'</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，如果replacement是一个字符串，则处理其中的任何反斜杠转义。也就是说，<code>\n</code>被转换为单个换行符，<code>\r</code> 被转换为回车符，依此类推。</p><p>还有一种语法用于引用由<code>(?P&lt;name&gt;...)</code>语法定义的命名组。<code>\g&lt;name&gt;</code> 将使用名称为<code>name</code> 的组匹配的子字符串，<code>\g&lt;number&gt;</code> 使用相应的组号(后向引用)，因此<code>\g&lt;2&gt;</code> 等同于<code>\2</code> ，但在诸如<code>\g&lt;2&gt;0</code> 之类的替换字符串中并不模糊。而<code>\20</code> 则被解释为对组20捕获的内容惊醒引用，而不是对组2的引用，因此不建议使用<code>\20</code> 这种用法，以下几种用法都是等效的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">player = <span class="string">"James&#123;Forward&#125; Rondo&#123;Guard&#125; Cousins&#123;Center&#125;"</span></span><br><span class="line"></span><br><span class="line">p = re.compile(<span class="string">r"\w+&#123;(?P&lt;position&gt;[^&#125;]*)&#125;"</span>)</span><br><span class="line"><span class="comment"># 把所有匹配正则的子字符串替换成 player(\g&lt;position&gt;)</span></span><br><span class="line">p.sub(<span class="string">r"player(\g&lt;position&gt;)"</span>, player)</span><br><span class="line">[out]:</span><br><span class="line">    <span class="string">'player(Forward) player(Guard) player(Center)'</span></span><br><span class="line"></span><br><span class="line">p.sub(<span class="string">r"player(\g&lt;1&gt;)"</span>,player)</span><br><span class="line">[out]:</span><br><span class="line">    <span class="string">'player(Forward) player(Guard) player(Center)'</span></span><br><span class="line"></span><br><span class="line">p.sub(<span class="string">r"player(\1)"</span>, player)</span><br><span class="line">[out]:</span><br><span class="line">    <span class="string">'player(Forward) player(Guard) player(Center)'</span></span><br></pre></td></tr></table></figure><p>此外，replacement也可以是一个函数，它可以为你提供更多控制。如果replacement是一个函数，则为patter的每次非重叠出现将调用该函数。在每次调用时，函数都会传递一个匹配的匹配对象参数，并可以使用此信息计算所需的替换字符串并将其返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现将句中的正数转换为浮点数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transfer</span><span class="params">(match)</span>:</span></span><br><span class="line">    value = int(match.group())</span><br><span class="line">    after_transfer = float(value)</span><br><span class="line">    <span class="comment"># 字符类型转换</span></span><br><span class="line">    <span class="keyword">return</span> str(after_transfer)</span><br><span class="line"></span><br><span class="line">raw = <span class="string">"James scored 33 points and Davis scored 29 points"</span></span><br><span class="line">p = re.compile(<span class="string">r"\d+"</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">需要注意的时，sub(replacement, string)，replacement一般都是一个字符型对象。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">p.sub(transfer, raw)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-基础字符&quot;&gt;&lt;a href=&quot;#1-基础字符&quot; class=&quot;headerlink&quot; title=&quot;1. 基础字符&quot;&gt;&lt;/a&gt;1. 基础字符&lt;/h1&gt;&lt;h2 id=&quot;1-1-元字符&quot;&gt;&lt;a href=&quot;#1-1-元字符&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="Python基础" scheme="http://yoursite.com/categories/Python%E5%9F%BA%E7%A1%80/"/>
    
    
  </entry>
  
  <entry>
    <title>leetcode-0019-删除链表的倒数第N个个节点</title>
    <link href="http://yoursite.com/2019/06/04/leetcode-0019-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%ACN%E4%B8%AA%E4%B8%AA%E8%8A%82%E7%82%B9/"/>
    <id>http://yoursite.com/2019/06/04/leetcode-0019-删除链表的倒数第N个个节点/</id>
    <published>2019-06-04T06:32:20.000Z</published>
    <updated>2019-07-22T12:30:01.334Z</updated>
    
    <content type="html"><![CDATA[<h2 id="题目表述"><a href="#题目表述" class="headerlink" title="[题目表述]"></a>[题目表述]</h2><p>给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。</p><p>示例：</p><p>给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2.</p><p>当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.<br>说明：</p><p>给定的 n 保证是有效的。</p><p>进阶：</p><p>你能尝试使用一趟扫描实现吗？</p><pre><code>    def removeNthFromEnd_one_iter(self, head, n):        dummy = ListNode(0)    dummy.next = head    first = dummy    second = dummy    while n &gt;= 0:        first = first.next        n -= 1    while first:        second = second.next        first = first.next    second.next = second.next.next    return dummy.next</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;题目表述&quot;&gt;&lt;a href=&quot;#题目表述&quot; class=&quot;headerlink&quot; title=&quot;[题目表述]&quot;&gt;&lt;/a&gt;[题目表述]&lt;/h2&gt;&lt;p&gt;给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。&lt;/p&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;p&gt;给定一个链表
      
    
    </summary>
    
      <category term="leetcode刷题" scheme="http://yoursite.com/categories/leetcode%E5%88%B7%E9%A2%98/"/>
    
    
  </entry>
  
</feed>
